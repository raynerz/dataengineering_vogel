{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[4]\") \\\n",
    "            .appName(\"bikerental\") \\\n",
    "            .getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from pyspark.sql.functions import dayofmonth\n",
    "from pyspark.sql.functions import month\n",
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql.functions import expr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: string (nullable = true)\n",
      " |-- long: string (nullable = true)\n",
      " |-- dockcount: string (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stationDF = spark.read.csv(\"file:/home/spark/Develop/data/201508_station_data.csv\", header=True)\n",
    "stationDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert station_id from string to long\n",
    "stationDF = stationDF.withColumnRenamed(\"station_id\", \"station_id_old\")\n",
    "stationDF = stationDF.withColumn(\"station_id\", col(\"station_id_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dockcount from string to long\n",
    "stationDF = stationDF.withColumnRenamed(\"dockcount\", \"dockcount_old\")\n",
    "stationDF = stationDF.withColumn(\"dockcount\", col(\"dockcount_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dockcount: long (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# omit unused data\n",
    "stationDF = stationDF.selectExpr(\"station_id\", \"name\", \"dockcount\", \"landmark\")\n",
    "stationDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register as table\n",
    "stationDF.createOrReplaceTempView(\"station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Start Station: string (nullable = true)\n",
      " |-- Start Terminal: string (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Station: string (nullable = true)\n",
      " |-- End Terminal: string (nullable = true)\n",
      " |-- Bike #: string (nullable = true)\n",
      " |-- Subscriber Type: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tripDF = spark.read.csv(\"file:/home/spark/Develop/data/201508_trip_data.csv\", header=True)\n",
    "tripDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert trip id from string to long\n",
    "tripDF = tripDF.withColumnRenamed(\"Trip ID\", \"trip_id_old\")\n",
    "tripDF = tripDF.withColumn(\"trip_id\", col(\"trip_id_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start date from string to date\n",
    "tripDF = tripDF.withColumnRenamed(\"Start Date\", \"start_date_old\")\n",
    "tripDF = tripDF.withColumn(\"start_date\", to_timestamp(col(\"start_date_old\"), \"MM/dd/yyyy HH:mm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add explicit day, month, and year columns for easier processing\n",
    "tripDF = tripDF.withColumn(\"start_date_day\", dayofmonth(col(\"start_date\")))\n",
    "tripDF = tripDF.withColumn(\"start_date_month\", month(col(\"start_date\")))\n",
    "tripDF = tripDF.withColumn(\"start_date_year\", year(col(\"start_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert start terminal/station from string to long\n",
    "tripDF = tripDF.withColumnRenamed(\"Start Terminal\", \"start_station_id_old\")\n",
    "tripDF = tripDF.withColumn(\"start_station_id\", col(\"start_station_id_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert end date from string to date\n",
    "tripDF = tripDF.withColumnRenamed(\"End Date\", \"end_date_old\")\n",
    "tripDF = tripDF.withColumn(\"end_date\", to_timestamp(col(\"end_date_old\"), \"MM/dd/yyyy HH:mm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert end terminal/station from string to long\n",
    "tripDF = tripDF.withColumnRenamed(\"End Terminal\", \"end_station_id_old\")\n",
    "tripDF = tripDF.withColumn(\"end_station_id\", col(\"end_station_id_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert duration from string to long\n",
    "tripDF = tripDF.withColumnRenamed(\"Duration\", \"duration_old\")\n",
    "tripDF = tripDF.withColumn(\"duration\", col(\"duration_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bike # from string to long\n",
    "tripDF = tripDF.withColumnRenamed(\"Bike #\", \"bike_old\")\n",
    "tripDF = tripDF.withColumn(\"bike\", col(\"bike_old\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: long (nullable = true)\n",
      " |-- duration: long (nullable = true)\n",
      " |-- start_date: timestamp (nullable = true)\n",
      " |-- start_date_day: integer (nullable = true)\n",
      " |-- start_date_month: integer (nullable = true)\n",
      " |-- start_date_year: integer (nullable = true)\n",
      " |-- start_station_id: long (nullable = true)\n",
      " |-- end_date: timestamp (nullable = true)\n",
      " |-- end_station_id: long (nullable = true)\n",
      " |-- bike: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Omit unused data\n",
    "tripDF = tripDF.selectExpr(\"trip_id\", \"duration\", \"start_date\", \"start_date_day\", \"start_date_month\", \"start_date_year\", \"start_station_id\", \"end_date\", \"end_station_id\", \"bike\")\n",
    "tripDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register as table\n",
    "tripDF.createOrReplaceTempView(\"trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tripDF.selectExpr(\"bike\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Rental Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationDF.where(\"landmark = \\\"San Francisco\\\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Station with the most Number of Docks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(station_id=2, dockcount=27)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF = spark.sql(\"SELECT station_id, dockcount \"+\\\n",
    "                     \"FROM station \"+\\\n",
    "                     \"ORDER BY dockcount DESC \"+\\\n",
    "                     \"LIMIT 1\")\n",
    "resultDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(station_id=61, dockcount=27)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF = spark.sql(\"SELECT station_id, dockcount \"+\\\n",
    "                     \"FROM station \"+\\\n",
    "                     \"WHERE landmark = \\\"San Francisco\\\" \"+\\\n",
    "                     \"ORDER BY dockcount DESC \"+\\\n",
    "                     \"LIMIT 1\")\n",
    "resultDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration of Bike Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(duration_avg=1046.0326611172604)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF = spark.sql(\"SELECT avg(duration) as duration_avg FROM trip\")\n",
    "resultDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(duration_min=60)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF = spark.sql(\"SELECT min(duration) as duration_min FROM trip\")\n",
    "resultDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(duration_max=17270400)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF = spark.sql(\"SELECT max(duration) as duration_max FROM trip\")\n",
    "resultDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Bike Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354152"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall\n",
    "tripDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_station_id=70, nbr_trips=26304),\n",
       " Row(start_station_id=69, nbr_trips=21758),\n",
       " Row(start_station_id=50, nbr_trips=17255),\n",
       " Row(start_station_id=55, nbr_trips=14436),\n",
       " Row(start_station_id=60, nbr_trips=14158),\n",
       " Row(start_station_id=61, nbr_trips=14026),\n",
       " Row(start_station_id=65, nbr_trips=13752),\n",
       " Row(start_station_id=74, nbr_trips=13687),\n",
       " Row(start_station_id=67, nbr_trips=11885),\n",
       " Row(start_station_id=77, nbr_trips=11431)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per station\n",
    "resultDF = spark.sql(\"SELECT start_station_id, count(trip_id) as nbr_trips \"+\\\n",
    "                     \"FROM trip \"+\\\n",
    "                     \"GROUP BY start_station_id \"+\\\n",
    "                     \"ORDER BY nbr_trips DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(bike=878, nbr_trips=1121),\n",
       " Row(bike=392, nbr_trips=1102),\n",
       " Row(bike=489, nbr_trips=1101),\n",
       " Row(bike=463, nbr_trips=1085),\n",
       " Row(bike=532, nbr_trips=1074),\n",
       " Row(bike=558, nbr_trips=1071),\n",
       " Row(bike=306, nbr_trips=1060),\n",
       " Row(bike=29, nbr_trips=1057),\n",
       " Row(bike=66, nbr_trips=1053),\n",
       " Row(bike=589, nbr_trips=1052)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per bike\n",
    "resultDF = spark.sql(\"SELECT bike, count(trip_id) as nbr_trips \"+\\\n",
    "                     \"FROM trip \"+\\\n",
    "                     \"GROUP BY bike \"+\\\n",
    "                     \"ORDER BY nbr_trips DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roundtrips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029015789830355326\n"
     ]
    }
   ],
   "source": [
    "# overall\n",
    "resultDF = spark.sql(\"SELECT trip_id \"+\\\n",
    "                     \"FROM trip \"+\\\n",
    "                     \"WHERE start_station_id = end_station_id\")\n",
    "print(float(resultDF.count())/tripDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_station_id=35, roundtrip_percentage=0.5752066115702479),\n",
       " Row(start_station_id=23, roundtrip_percentage=0.3700787401574803),\n",
       " Row(start_station_id=3, roundtrip_percentage=0.2441860465116279),\n",
       " Row(start_station_id=36, roundtrip_percentage=0.2125),\n",
       " Row(start_station_id=24, roundtrip_percentage=0.19491525423728814),\n",
       " Row(start_station_id=14, roundtrip_percentage=0.160741885625966),\n",
       " Row(start_station_id=21, roundtrip_percentage=0.14814814814814814),\n",
       " Row(start_station_id=34, roundtrip_percentage=0.14516129032258066),\n",
       " Row(start_station_id=37, roundtrip_percentage=0.11458333333333333),\n",
       " Row(start_station_id=25, roundtrip_percentage=0.11238532110091744)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per station\n",
    "tripsPerStationDF = spark.sql(\"SELECT count(trip_id) as nbr_trips, start_station_id \"+\\\n",
    "                              \"FROM trip \"+\\\n",
    "                              \"GROUP BY start_station_id\")\n",
    "tripsPerStationDF.createOrReplaceTempView(\"trips_per_station\")\n",
    "\n",
    "roundtripsPerStationDF = spark.sql(\"SELECT count(trip_id) as nbr_roundtrips, start_station_id \"+\\\n",
    "                                   \"FROM trip \"+\\\n",
    "                                   \"WHERE start_station_id = end_station_id \"+\\\n",
    "                                   \"GROUP BY start_station_id\")\n",
    "roundtripsPerStationDF.createOrReplaceTempView(\"roundtrips_per_station\")\n",
    "\n",
    "resultDF = spark.sql(\"SELECT trips_per_station.start_station_id, nbr_roundtrips / nbr_trips as roundtrip_percentage \"+\\\n",
    "                     \"FROM trips_per_station JOIN roundtrips_per_station ON trips_per_station.start_station_id = roundtrips_per_station.start_station_id \"+\\\n",
    "                     \"ORDER BY roundtrip_percentage DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Bike Trips Per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_date_year=2014, start_date_month=9, start_date_day=15, nbr_trips=1516),\n",
       " Row(start_date_year=2014, start_date_month=10, start_date_day=29, nbr_trips=1496),\n",
       " Row(start_date_year=2014, start_date_month=10, start_date_day=14, nbr_trips=1496),\n",
       " Row(start_date_year=2015, start_date_month=8, start_date_day=26, nbr_trips=1465),\n",
       " Row(start_date_year=2014, start_date_month=10, start_date_day=16, nbr_trips=1462),\n",
       " Row(start_date_year=2014, start_date_month=10, start_date_day=2, nbr_trips=1452),\n",
       " Row(start_date_year=2015, start_date_month=7, start_date_day=28, nbr_trips=1451),\n",
       " Row(start_date_year=2015, start_date_month=8, start_date_day=27, nbr_trips=1443),\n",
       " Row(start_date_year=2014, start_date_month=9, start_date_day=16, nbr_trips=1438),\n",
       " Row(start_date_year=2015, start_date_month=6, start_date_day=11, nbr_trips=1437)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall\n",
    "resultDF = spark.sql(\"SELECT start_date_year, start_date_month, start_date_day, count(trip_id) as nbr_trips \" +\\\n",
    "                     \"FROM trip \" +\\\n",
    "                     \"GROUP BY start_date_year, start_date_month, start_date_day \" +\\\n",
    "                     \"ORDER BY nbr_trips DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_date_year=2014, start_date_month=10, start_date_day=5, nbr_trips=18),\n",
       " Row(start_date_year=2014, start_date_month=9, start_date_day=7, nbr_trips=12),\n",
       " Row(start_date_year=2015, start_date_month=7, start_date_day=11, nbr_trips=11),\n",
       " Row(start_date_year=2015, start_date_month=4, start_date_day=11, nbr_trips=11),\n",
       " Row(start_date_year=2015, start_date_month=1, start_date_day=4, nbr_trips=10),\n",
       " Row(start_date_year=2015, start_date_month=8, start_date_day=8, nbr_trips=9),\n",
       " Row(start_date_year=2015, start_date_month=7, start_date_day=21, nbr_trips=9),\n",
       " Row(start_date_year=2015, start_date_month=7, start_date_day=26, nbr_trips=9),\n",
       " Row(start_date_year=2014, start_date_month=9, start_date_day=13, nbr_trips=8),\n",
       " Row(start_date_year=2015, start_date_month=8, start_date_day=9, nbr_trips=8)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in Palo Alto\n",
    "paloAltoDF = spark.sql(\"SELECT station_id \" +\\\n",
    "                       \"FROM station \" +\\\n",
    "                       \"WHERE landmark = \\\"Palo Alto\\\"\")\n",
    "paloAltoDF.createOrReplaceTempView(\"paloalto\")\n",
    " \n",
    "resultDF = spark.sql(\"SELECT start_date_year, start_date_month, start_date_day, count(trip_id) as nbr_trips \" +\\\n",
    "                     \"FROM trip JOIN paloalto ON trip.start_station_id = paloalto.station_id \" +\\\n",
    "                     \"WHERE start_station_id = end_station_id \" +\\\n",
    "                     \"GROUP BY start_date_year, start_date_month, start_date_day \" +\\\n",
    "                     \"ORDER BY nbr_trips DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(start_date_year=2014, start_date_month=9, start_date_day=15, nbr_trips=1516)\n",
      "Row(start_date_year=2014, start_date_month=10, start_date_day=29, nbr_trips=1496)\n",
      "Row(start_date_year=2014, start_date_month=11, start_date_day=6, nbr_trips=1410)\n",
      "Row(start_date_year=2014, start_date_month=12, start_date_day=8, nbr_trips=1363)\n"
     ]
    }
   ],
   "source": [
    "# per month\n",
    "months = spark.sql(\"SELECT DISTINCT start_date_month \" +\\\n",
    "                     \"FROM trip \" +\\\n",
    "                     \"WHERE start_date_year = 2014 \" +\\\n",
    "                     \"ORDER BY start_date_month\").collect()\n",
    "\n",
    "for r in months:\n",
    "    print(spark.sql(\"SELECT start_date_year, start_date_month, start_date_day, count(trip_id) as nbr_trips \" +\\\n",
    "              \"FROM trip \" +\\\n",
    "              \"WHERE start_date_year = 2014 AND start_date_month = \" + str(r[\"start_date_month\"]) + \" \" +\\\n",
    "              \"GROUP BY start_date_year, start_date_month, start_date_day \" +\\\n",
    "              \"ORDER BY nbr_trips DESC \" + \\\n",
    "              \"LIMIT 1\").first())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(start_date_day=15, start_date_month=9, nbr_trips=1516),\n",
       " Row(start_date_day=16, start_date_month=9, nbr_trips=1438),\n",
       " Row(start_date_day=17, start_date_month=9, nbr_trips=1429),\n",
       " Row(start_date_day=3, start_date_month=9, nbr_trips=1404),\n",
       " Row(start_date_day=4, start_date_month=9, nbr_trips=1389),\n",
       " Row(start_date_day=11, start_date_month=9, nbr_trips=1381),\n",
       " Row(start_date_day=9, start_date_month=9, nbr_trips=1362),\n",
       " Row(start_date_day=23, start_date_month=9, nbr_trips=1362),\n",
       " Row(start_date_day=22, start_date_month=9, nbr_trips=1353),\n",
       " Row(start_date_day=10, start_date_month=9, nbr_trips=1351)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing all days for a month\n",
    "resultDF = spark.sql(\"SELECT start_date_day, start_date_month, count(trip_id) as nbr_trips \" +\\\n",
    "                     \"FROM trip \" +\\\n",
    "                     \"WHERE start_date_year = 2014 \" +\\\n",
    "                     \"GROUP BY start_date_month, start_date_day \" +\\\n",
    "                     \"ORDER BY start_date_month, nbr_trips DESC\")\n",
    "resultDF.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [start_date_month#163 ASC NULLS FIRST, nbr_trips#610L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(start_date_month#163 ASC NULLS FIRST, nbr_trips#610L DESC NULLS LAST, 200)\n",
      "   +- *(2) HashAggregate(keys=[start_date_month#163, start_date_day#148], functions=[count(trip_id#108L)])\n",
      "      +- Exchange hashpartitioning(start_date_month#163, start_date_day#148, 200)\n",
      "         +- *(1) HashAggregate(keys=[start_date_month#163, start_date_day#148], functions=[partial_count(trip_id#108L)])\n",
      "            +- *(1) Project [cast(Trip ID#74 as bigint) AS trip_id#108L, dayofmonth(cast(cast(unix_timestamp(Start Date#76, MM/dd/yyyy HH:mm, Some(Europe/Zurich)) as timestamp) as date)) AS start_date_day#148, month(cast(cast(unix_timestamp(Start Date#76, MM/dd/yyyy HH:mm, Some(Europe/Zurich)) as timestamp) as date)) AS start_date_month#163]\n",
      "               +- *(1) Filter (year(cast(cast(unix_timestamp(Start Date#76, MM/dd/yyyy HH:mm, Some(Europe/Zurich)) as timestamp) as date)) = 2014)\n",
      "                  +- *(1) FileScan csv [Trip ID#74,Start Date#76] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/spark/Develop/data/201508_trip_data.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Trip ID:string,Start Date:string>\n"
     ]
    }
   ],
   "source": [
    "resultDF.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
